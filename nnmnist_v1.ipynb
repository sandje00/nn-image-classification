{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nnmnist_v1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sandje00/nn-image-classification/blob/master/nnmnist_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWGrQNpuPJUS",
        "colab_type": "text"
      },
      "source": [
        "# Neural network for recognizing handwritten digits\n",
        "\n",
        "Source: [How To Build a Neural Network to Recognize Handwritten Digits with TensorFlow](https://www.digitalocean.com/community/tutorials/how-to-build-a-neural-network-to-recognize-handwritten-digits-with-tensorflow) by **Ellie Birbeck**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UGxWI76QJDq",
        "colab_type": "text"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aN4K7js3POtU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "from google.colab import files\n",
        "from IPython.display import Image as Show"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWpdWiIAR-6X",
        "colab_type": "text"
      },
      "source": [
        "***One-hot-encoding***: represents the labels, i. e. actual digit drawn. Each label is represented with 1D vector of size 10 with the element of the index that corresponds to the digit is set to `1`, while others are set to `0`.\n",
        "\n",
        "Images are represented with 1D vector of size 784 px (28x28) that contains values from 0 to 255, since the pictures are grayscale."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5eq9NidQdci",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "N8XxoHi1VFlQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b413d937-1d62-4946-c6be-c0140b412b4e"
      },
      "source": [
        "n_train = mnist.train.num_examples\n",
        "n_validation = mnist.validation.num_examples\n",
        "n_test = mnist.test.num_examples\n",
        "\n",
        "print(\"Training examples: \" + str(n_train))\n",
        "print(\"Validation examples: \" + str(n_validation))\n",
        "print(\"Testing examples: \" + str(n_test))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training examples: 55000\n",
            "Validation examples: 5000\n",
            "Testing examples: 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oH2u58r2V3Qx",
        "colab_type": "text"
      },
      "source": [
        "### Neural network:\n",
        "\n",
        "\n",
        "*   number of layers\n",
        "*   number of units in each layer\n",
        "*   how units are connected between layers\n",
        "\n",
        "Input, output and *hidden* (between Input and Output) layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-FQUISHWpka",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_input = 784 # represents 784 (28x28) pixels\n",
        "n_hidden1 = 512\n",
        "n_hidden2 = 256\n",
        "n_hidden3 = 128\n",
        "n_output = 10 # represents recognized digit (0 - 9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "At-W6txOXbVe",
        "colab_type": "text"
      },
      "source": [
        "### Hyperparameters (NN config)\n",
        "\n",
        "**Learning rate** represents how much the parameters will adjust at each step of the learning process (after each network traversal weights are slightly adjusted).\n",
        "**The number of iterations** represents how many times we go through the training step.\n",
        "**The batch size** represents how many training examples we are using at each step\n",
        "**The dropout variable** in the final hidden layer to give each unit a 50% chance of being eliminated at every training step (overfitting prevention)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8C2ZyjfNY8HL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 1e-4\n",
        "n_iterations = 1000\n",
        "batch_size = 128\n",
        "dropout = 0.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aqwWF16ZnP9",
        "colab_type": "text"
      },
      "source": [
        "### Building the Tensorflow Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ek8nfNL9ZsSI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = tf.placeholder(\"float\", [None, n_input]) # feeding in an undefined number of 784-pixel images\n",
        "Y = tf.placeholder(\"float\", [None, n_output]) # undefined number of label outputs, with 10 possible classes\n",
        "keep_prob = tf.placeholder(tf.float32) # controlling the dropout rate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNUZM-FparFl",
        "colab_type": "text"
      },
      "source": [
        "`weight` and `bias` - will be updated within the training process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSVDd-mhbA2z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights = {\n",
        "    'w1': tf.Variable(tf.truncated_normal([n_input, n_hidden1], stddev=0.1)),\n",
        "    'w2': tf.Variable(tf.truncated_normal([n_hidden1, n_hidden2], stddev=0.1)),\n",
        "    'w3': tf.Variable(tf.truncated_normal([n_hidden2, n_hidden3], stddev=0.1)),\n",
        "    'out': tf.Variable(tf.truncated_normal([n_hidden3, n_output], stddev=0.1)),\n",
        "}\n",
        "\n",
        "biases = {\n",
        "    'b1': tf.Variable(tf.constant(0.1, shape=[n_hidden1])),\n",
        "    'b2': tf.Variable(tf.constant(0.1, shape=[n_hidden2])),\n",
        "    'b3': tf.Variable(tf.constant(0.1, shape=[n_hidden3])),\n",
        "    'out': tf.Variable(tf.constant(0.1, shape=[n_output]))\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgjVw9wbb9HM",
        "colab_type": "text"
      },
      "source": [
        "Each hidden layer executes matrix multiplication on the previous layer’s outputs and the current layer’s weights, and adds the bias to these values. At the last hidden layer, a dropout operation using `keep_prob` value of 0.5 will be applied"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbBX2g2Kb72x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layer_1 = tf.add(tf.matmul(X, weights['w1']), biases['b1'])\n",
        "layer_2 = tf.add(tf.matmul(layer_1, weights['w2']), biases['b2'])\n",
        "layer_3 = tf.add(tf.matmul(layer_2, weights['w3']), biases['b3'])\n",
        "layer_drop = tf.nn.dropout(layer_3, keep_prob)\n",
        "output_layer = tf.matmul(layer_3, weights['out']) + biases['out']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2J72XB6cjMe",
        "colab_type": "text"
      },
      "source": [
        "**Cross entropy** - the loss function that we want to optimize; quantifies the difference between two probability distributions (the predictions and the labels)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-j1PhHT4c7kG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cross_entropy = tf.reduce_mean(\n",
        "    tf.nn.softmax_cross_entropy_with_logits(\n",
        "        labels=Y, logits=output_layer\n",
        "        ))\n",
        "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozQ0TXZYdMbM",
        "colab_type": "text"
      },
      "source": [
        "**Adam optimizer** - he optimization algorithm which will be used to minimize the loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZJVvI1ydVsH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "al0_wgM3eYlj",
        "colab_type": "text"
      },
      "source": [
        "### Training and testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAxzKtNWecVU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# which images are being predicted correctly by looking at the output_layer (predictions) and Y (labels)\n",
        "correct_pred = tf.equal(tf.argmax(output_layer, 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "# init the tf session\n",
        "init = tf.global_variables_initializer()\n",
        "sess = tf.Session()\n",
        "sess.run(init)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hA3DCgtLfiBx",
        "colab_type": "text"
      },
      "source": [
        "#### For a `n_iterations`:\n",
        "* Propagate values forward through the network\n",
        "* Compute the loss\n",
        "* Propagate values backward through the network\n",
        "* Update the parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I84155r4gNs-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "70eee24e-ea5e-4b63-c838-a4af6974aba6"
      },
      "source": [
        "# mini batches training\n",
        "for i in range(n_iterations):\n",
        "    batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
        "    sess.run(train_step, feed_dict={\n",
        "        X: batch_x, Y: batch_y, keep_prob: dropout\n",
        "        })\n",
        "\n",
        "    # each 100 iterations print loss and accuracy\n",
        "    if i % 100 == 0:\n",
        "        minibatch_loss, minibatch_accuracy = sess.run(\n",
        "            [cross_entropy, accuracy],\n",
        "            feed_dict={X: batch_x, Y: batch_y, keep_prob: 1.0}\n",
        "            )\n",
        "        print(\n",
        "            \"Iteration\",\n",
        "            str(i),\n",
        "            \"\\t| Loss =\",\n",
        "            str(minibatch_loss),\n",
        "            \"\\t| Accuracy =\",\n",
        "            str(minibatch_accuracy)\n",
        "            )"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 0 \t| Loss = 3.3607488 \t| Accuracy = 0.140625\n",
            "Iteration 100 \t| Loss = 0.5069246 \t| Accuracy = 0.8515625\n",
            "Iteration 200 \t| Loss = 0.3140415 \t| Accuracy = 0.9140625\n",
            "Iteration 300 \t| Loss = 0.34024987 \t| Accuracy = 0.921875\n",
            "Iteration 400 \t| Loss = 0.40706205 \t| Accuracy = 0.8984375\n",
            "Iteration 500 \t| Loss = 0.38191426 \t| Accuracy = 0.8671875\n",
            "Iteration 600 \t| Loss = 0.21404745 \t| Accuracy = 0.9375\n",
            "Iteration 700 \t| Loss = 0.3643704 \t| Accuracy = 0.8984375\n",
            "Iteration 800 \t| Loss = 0.29131815 \t| Accuracy = 0.9296875\n",
            "Iteration 900 \t| Loss = 0.3233501 \t| Accuracy = 0.8828125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOMxqZETgz-i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9e74849d-0870-456b-eefb-73661553c875"
      },
      "source": [
        "test_accuracy = sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels, keep_prob: 1.0})\n",
        "print(\"\\nAccuracy on test set:\", test_accuracy)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Accuracy on test set: 0.9166\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuCQwf9s_0MN",
        "colab_type": "text"
      },
      "source": [
        "### Demo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqbsY6cDAlC4",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "6167729d-4e56-46e4-f1ef-fae11b6e6a3c"
      },
      "source": [
        "# Uploading the test image\n",
        "files.upload()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f58d0de2-2daa-43d3-a2d3-47ef9b81e6d2\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-f58d0de2-2daa-43d3-a2d3-47ef9b81e6d2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving test_img.png to test_img.png\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'test_img.png': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\x1c\\x10\\x04\\x00\\x00\\x00\\x88\\x94\\xcb\\\\\\x00\\x00\\x00\\x02bKGD\\xff\\xff\\x14\\xab1\\xcd\\x00\\x00\\x00\\tpHYs\\x00\\x00\\x00H\\x00\\x00\\x00H\\x00F\\xc9k>\\x00\\x00\\x00\\tvpAg\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\x1c\\x00\\x87\\xb1\"\\xb4\\x00\\x00\\x00\\x93IDATH\\xc7c\\xf8Og\\xc00j\\xe1\\xa0\\xb0\\xb0\\xa1\\x01\\x82ij!\\xcc\\x12GGTL\\x13\\x0ba\\x16\\xa1\\xfb\\x0c&FU\\x0b?|\\xf8\\xff\\xdf\\xc1\\x01B\\xe3r\\x08\\xd5}\\xf8\\xe0\\x01n9R}Iq*%5\\x01\\x8dZHv\\x82\\xa2\\xba\\x85\\xb0\\x14ZXH\\x87\\x92\\x06\\x96\\xe9\\xc9)mH\\xb2\\xb0\\xb2\\x12\\x12\\x84 \\x9a\\xa6e)r\\x91\\x86/ORl!\\xb2E\\xe4\\x16\\xd6D[\\x08\\xb2@Q\\x11\\xb5\\x0c%\\x84\\xa9\\xe2Cb1\\xb1\\xb5\\x07U+`b|9\\xda\\xc4\\x18\\xb5p\\xd4B\\x0c\\x00\\x00w^\\xe3\\xa8y\\x93\\xab\\x1a\\x00\\x00\\x00%tEXtdate:create\\x002016-08-27T03:02:30+09:00bT\\x84\\xe2\\x00\\x00\\x00%tEXtdate:modify\\x002016-08-27T03:02:30+09:00\\x13\\t<^\\x00\\x00\\x00\\x17tEXtpng:bit-depth-written\\x00\\x08\\xa7\\xc4,\\xf2\\x00\\x00\\x00\\x00IEND\\xaeB`\\x82'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gci9CgQoWg7s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 45
        },
        "outputId": "aa936b57-9822-4ad5-be29-a3718220b7df"
      },
      "source": [
        "Show('/content/test_img.png')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcEAQAAACIlMtcAAAAAmJLR0T//xSrMc0AAAAJcEhZcwAA\nAEgAAABIAEbJaz4AAAAJdnBBZwAAABwAAAAcAIexIrQAAACTSURBVEjHY/hPZ8AwauGgsLChAYJp\naiHMEkdHVEwTC2EWofsMJkZVCz98+P/fwQFC43II1X344AFuOVJ9SXEqJTUBjVpIdoKiuoWwFFpY\nSIeSBpbpySltSLKwshIShCCapmUpcpGGL09SbCGyReQW1kRbCLJAURG1DCWEqeJDYjGxtQdVK2Bi\nfDnaxBi1cNRCDAAAd17jqHmTqxoAAAAldEVYdGRhdGU6Y3JlYXRlADIwMTYtMDgtMjdUMDM6MDI6\nMzArMDk6MDBiVITiAAAAJXRFWHRkYXRlOm1vZGlmeQAyMDE2LTA4LTI3VDAzOjAyOjMwKzA5OjAw\nEwk8XgAAABd0RVh0cG5nOmJpdC1kZXB0aC13cml0dGVuAAinxCzyAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQQ40qhTA4KC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = np.invert(Image.open(\"test_img.png\").convert('L')).ravel()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmdLIkl0Bsi6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bfbf6c78-616f-404e-ed83-a980390c2997"
      },
      "source": [
        "prediction = sess.run(tf.argmax(output_layer, 1), feed_dict={X: [img]})\n",
        "print (\"Prediction for test image:\", np.squeeze(prediction))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction for test image: 2\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}